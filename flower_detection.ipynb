{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2TrJJy5SO12"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Encoding and Split data into Train/Test Sets\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tensorflow Keras CNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad,Adadelta,RMSprop\n",
        "\n",
        "#Plot Images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "folder_dir = '/content/drive/MyDrive/Image_CLF_Datasets/flowers'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeES559_SX63"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "label = []\n",
        "\n",
        "#crop the image to 128 x 128\n",
        "SIZE = 128\n",
        "\n",
        "for folder in os.listdir(folder_dir):\n",
        "    for file in os.listdir(os.path.join(folder_dir, folder)):\n",
        "        if file.endswith(\"jpg\"):\n",
        "            label.append(folder)\n",
        "            img = cv2.imread(os.path.join(folder_dir, folder, file))\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            im = cv2.resize(img_rgb, (SIZE,SIZE))\n",
        "            data.append(im)\n",
        "        else:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIO5ZRVUFHM"
      },
      "outputs": [],
      "source": [
        "# Convert data into numerical values\n",
        "data_arr = np.array(data)\n",
        "label_arr = np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q18M-p05UShR"
      },
      "outputs": [],
      "source": [
        "# print(data_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exgFh5qoUmPo"
      },
      "outputs": [],
      "source": [
        "# print(label_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpYVgxvQUqzF",
        "outputId": "d4c21a1d-5c30-41fa-a883-c09479722315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 ... 2 2 2]\n",
            "[[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Use label encoder and normalize the data\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(label_arr)\n",
        "print(y)\n",
        "y = to_categorical(y,5)\n",
        "print(y)\n",
        "X = data_arr/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx_cqlnvU5YV"
      },
      "outputs": [],
      "source": [
        "#split the dataset into 80% training and 20% testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lomGICGJU5bv"
      },
      "outputs": [],
      "source": [
        "# Build Neura Network for flower classification:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu', input_shape = (SIZE, SIZE,3) ))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"Same\", activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"Same\", activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"Same\", activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ZcghgLb5Vz",
        "outputId": "925058c9-58e1-4b86-d3ea-721f72deeeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 131072)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16777344  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,156,741\n",
            "Trainable params: 17,156,741\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CSmV08tZcBx"
      },
      "outputs": [],
      "source": [
        "# We need to create more training images to prevent overfitting before compiling\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    zoom_range = 0.20,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range = 0.3,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLHC3sEvaNXv",
        "outputId": "871a22b9-35fd-4398-b92a-63bce2af7818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-9f23205af313>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "95/95 - 33s - loss: 1.4864 - accuracy: 0.3337 - val_loss: 1.3588 - val_accuracy: 0.4275 - 33s/epoch - 350ms/step\n",
            "Epoch 2/64\n",
            "95/95 - 18s - loss: 1.3073 - accuracy: 0.4270 - val_loss: 1.1502 - val_accuracy: 0.5008 - 18s/epoch - 190ms/step\n",
            "Epoch 3/64\n",
            "95/95 - 17s - loss: 1.2149 - accuracy: 0.4912 - val_loss: 1.1588 - val_accuracy: 0.4923 - 17s/epoch - 178ms/step\n",
            "Epoch 4/64\n",
            "95/95 - 22s - loss: 1.1708 - accuracy: 0.5263 - val_loss: 1.0134 - val_accuracy: 0.6065 - 22s/epoch - 236ms/step\n",
            "Epoch 5/64\n",
            "95/95 - 16s - loss: 1.1398 - accuracy: 0.5366 - val_loss: 1.0349 - val_accuracy: 0.5895 - 16s/epoch - 173ms/step\n",
            "Epoch 6/64\n",
            "95/95 - 16s - loss: 1.0724 - accuracy: 0.5776 - val_loss: 0.9438 - val_accuracy: 0.6335 - 16s/epoch - 172ms/step\n",
            "Epoch 7/64\n",
            "95/95 - 16s - loss: 1.0730 - accuracy: 0.5796 - val_loss: 0.9443 - val_accuracy: 0.6397 - 16s/epoch - 170ms/step\n",
            "Epoch 8/64\n",
            "95/95 - 17s - loss: 1.0426 - accuracy: 0.5892 - val_loss: 0.9306 - val_accuracy: 0.6343 - 17s/epoch - 183ms/step\n",
            "Epoch 9/64\n",
            "95/95 - 17s - loss: 1.0124 - accuracy: 0.6071 - val_loss: 0.9509 - val_accuracy: 0.6312 - 17s/epoch - 177ms/step\n",
            "Epoch 10/64\n",
            "95/95 - 16s - loss: 0.9982 - accuracy: 0.6157 - val_loss: 0.8858 - val_accuracy: 0.6512 - 16s/epoch - 169ms/step\n",
            "Epoch 11/64\n",
            "95/95 - 16s - loss: 0.9849 - accuracy: 0.6114 - val_loss: 0.8952 - val_accuracy: 0.6543 - 16s/epoch - 169ms/step\n",
            "Epoch 12/64\n",
            "95/95 - 17s - loss: 0.9553 - accuracy: 0.6319 - val_loss: 0.8498 - val_accuracy: 0.6659 - 17s/epoch - 176ms/step\n",
            "Epoch 13/64\n",
            "95/95 - 17s - loss: 0.9470 - accuracy: 0.6385 - val_loss: 0.8593 - val_accuracy: 0.6705 - 17s/epoch - 177ms/step\n",
            "Epoch 14/64\n",
            "95/95 - 18s - loss: 0.9191 - accuracy: 0.6415 - val_loss: 0.8569 - val_accuracy: 0.6682 - 18s/epoch - 190ms/step\n",
            "Epoch 15/64\n",
            "95/95 - 17s - loss: 0.9229 - accuracy: 0.6415 - val_loss: 0.8789 - val_accuracy: 0.6644 - 17s/epoch - 176ms/step\n",
            "Epoch 16/64\n",
            "95/95 - 17s - loss: 0.9095 - accuracy: 0.6372 - val_loss: 0.8022 - val_accuracy: 0.6906 - 17s/epoch - 177ms/step\n",
            "Epoch 17/64\n",
            "95/95 - 16s - loss: 0.8862 - accuracy: 0.6657 - val_loss: 0.8997 - val_accuracy: 0.6551 - 16s/epoch - 170ms/step\n",
            "Epoch 18/64\n",
            "95/95 - 17s - loss: 0.8830 - accuracy: 0.6511 - val_loss: 0.8325 - val_accuracy: 0.6759 - 17s/epoch - 182ms/step\n",
            "Epoch 19/64\n",
            "95/95 - 16s - loss: 0.8615 - accuracy: 0.6660 - val_loss: 0.8074 - val_accuracy: 0.6860 - 16s/epoch - 169ms/step\n",
            "Epoch 20/64\n",
            "95/95 - 16s - loss: 0.8450 - accuracy: 0.6667 - val_loss: 0.8353 - val_accuracy: 0.6821 - 16s/epoch - 170ms/step\n",
            "Epoch 21/64\n",
            "95/95 - 17s - loss: 0.8392 - accuracy: 0.6786 - val_loss: 0.8596 - val_accuracy: 0.6744 - 17s/epoch - 181ms/step\n",
            "Epoch 22/64\n",
            "95/95 - 16s - loss: 0.8506 - accuracy: 0.6789 - val_loss: 0.7768 - val_accuracy: 0.6991 - 16s/epoch - 171ms/step\n",
            "Epoch 23/64\n",
            "95/95 - 16s - loss: 0.8185 - accuracy: 0.6769 - val_loss: 0.8002 - val_accuracy: 0.6821 - 16s/epoch - 169ms/step\n",
            "Epoch 24/64\n",
            "95/95 - 16s - loss: 0.8039 - accuracy: 0.6905 - val_loss: 0.8664 - val_accuracy: 0.6613 - 16s/epoch - 167ms/step\n",
            "Epoch 25/64\n",
            "95/95 - 16s - loss: 0.8022 - accuracy: 0.6945 - val_loss: 0.7692 - val_accuracy: 0.7006 - 16s/epoch - 171ms/step\n",
            "Epoch 26/64\n",
            "95/95 - 17s - loss: 0.8074 - accuracy: 0.6951 - val_loss: 0.7909 - val_accuracy: 0.6991 - 17s/epoch - 175ms/step\n",
            "Epoch 27/64\n",
            "95/95 - 17s - loss: 0.7901 - accuracy: 0.6908 - val_loss: 0.7522 - val_accuracy: 0.7091 - 17s/epoch - 175ms/step\n",
            "Epoch 28/64\n",
            "95/95 - 17s - loss: 0.7860 - accuracy: 0.6991 - val_loss: 0.7308 - val_accuracy: 0.7207 - 17s/epoch - 178ms/step\n",
            "Epoch 29/64\n",
            "95/95 - 19s - loss: 0.7840 - accuracy: 0.6931 - val_loss: 0.7278 - val_accuracy: 0.7207 - 19s/epoch - 199ms/step\n",
            "Epoch 30/64\n",
            "95/95 - 16s - loss: 0.7737 - accuracy: 0.7100 - val_loss: 0.7259 - val_accuracy: 0.7191 - 16s/epoch - 169ms/step\n",
            "Epoch 31/64\n",
            "95/95 - 16s - loss: 0.7632 - accuracy: 0.7074 - val_loss: 0.7564 - val_accuracy: 0.7091 - 16s/epoch - 169ms/step\n",
            "Epoch 32/64\n",
            "95/95 - 17s - loss: 0.7609 - accuracy: 0.7186 - val_loss: 0.7508 - val_accuracy: 0.7083 - 17s/epoch - 176ms/step\n",
            "Epoch 33/64\n",
            "95/95 - 17s - loss: 0.7368 - accuracy: 0.7216 - val_loss: 0.7835 - val_accuracy: 0.7006 - 17s/epoch - 176ms/step\n",
            "Epoch 34/64\n",
            "95/95 - 17s - loss: 0.7369 - accuracy: 0.7140 - val_loss: 0.8168 - val_accuracy: 0.6906 - 17s/epoch - 176ms/step\n",
            "Epoch 35/64\n",
            "95/95 - 16s - loss: 0.7256 - accuracy: 0.7296 - val_loss: 0.7120 - val_accuracy: 0.7261 - 16s/epoch - 168ms/step\n",
            "Epoch 36/64\n",
            "95/95 - 16s - loss: 0.7353 - accuracy: 0.7127 - val_loss: 0.7361 - val_accuracy: 0.7238 - 16s/epoch - 169ms/step\n",
            "Epoch 37/64\n",
            "95/95 - 16s - loss: 0.7316 - accuracy: 0.7153 - val_loss: 0.7502 - val_accuracy: 0.7076 - 16s/epoch - 169ms/step\n",
            "Epoch 38/64\n",
            "95/95 - 17s - loss: 0.7124 - accuracy: 0.7282 - val_loss: 0.7112 - val_accuracy: 0.7361 - 17s/epoch - 179ms/step\n",
            "Epoch 39/64\n",
            "95/95 - 17s - loss: 0.7160 - accuracy: 0.7335 - val_loss: 0.8228 - val_accuracy: 0.6929 - 17s/epoch - 182ms/step\n",
            "Epoch 40/64\n",
            "95/95 - 17s - loss: 0.6982 - accuracy: 0.7441 - val_loss: 0.7166 - val_accuracy: 0.7361 - 17s/epoch - 176ms/step\n",
            "Epoch 41/64\n",
            "95/95 - 17s - loss: 0.7103 - accuracy: 0.7272 - val_loss: 0.7102 - val_accuracy: 0.7191 - 17s/epoch - 175ms/step\n",
            "Epoch 42/64\n",
            "95/95 - 16s - loss: 0.6929 - accuracy: 0.7339 - val_loss: 0.7552 - val_accuracy: 0.7253 - 16s/epoch - 168ms/step\n",
            "Epoch 43/64\n",
            "95/95 - 17s - loss: 0.6896 - accuracy: 0.7418 - val_loss: 0.6883 - val_accuracy: 0.7338 - 17s/epoch - 176ms/step\n",
            "Epoch 44/64\n",
            "95/95 - 16s - loss: 0.6974 - accuracy: 0.7322 - val_loss: 0.6873 - val_accuracy: 0.7446 - 16s/epoch - 168ms/step\n",
            "Epoch 45/64\n",
            "95/95 - 17s - loss: 0.6900 - accuracy: 0.7372 - val_loss: 0.8418 - val_accuracy: 0.6991 - 17s/epoch - 174ms/step\n",
            "Epoch 46/64\n",
            "95/95 - 16s - loss: 0.6714 - accuracy: 0.7507 - val_loss: 0.7017 - val_accuracy: 0.7469 - 16s/epoch - 171ms/step\n",
            "Epoch 47/64\n",
            "95/95 - 17s - loss: 0.6707 - accuracy: 0.7382 - val_loss: 0.7425 - val_accuracy: 0.7168 - 17s/epoch - 177ms/step\n",
            "Epoch 48/64\n",
            "95/95 - 16s - loss: 0.6737 - accuracy: 0.7507 - val_loss: 0.7686 - val_accuracy: 0.7276 - 16s/epoch - 171ms/step\n",
            "Epoch 49/64\n",
            "95/95 - 16s - loss: 0.6736 - accuracy: 0.7448 - val_loss: 0.6800 - val_accuracy: 0.7515 - 16s/epoch - 169ms/step\n",
            "Epoch 50/64\n",
            "95/95 - 17s - loss: 0.6522 - accuracy: 0.7544 - val_loss: 0.7139 - val_accuracy: 0.7477 - 17s/epoch - 177ms/step\n",
            "Epoch 51/64\n",
            "95/95 - 16s - loss: 0.6540 - accuracy: 0.7550 - val_loss: 0.6849 - val_accuracy: 0.7593 - 16s/epoch - 171ms/step\n",
            "Epoch 52/64\n",
            "95/95 - 16s - loss: 0.6569 - accuracy: 0.7484 - val_loss: 0.7077 - val_accuracy: 0.7454 - 16s/epoch - 171ms/step\n",
            "Epoch 53/64\n",
            "95/95 - 17s - loss: 0.6478 - accuracy: 0.7531 - val_loss: 0.7798 - val_accuracy: 0.7145 - 17s/epoch - 176ms/step\n",
            "Epoch 54/64\n",
            "95/95 - 16s - loss: 0.6536 - accuracy: 0.7498 - val_loss: 0.7287 - val_accuracy: 0.7415 - 16s/epoch - 170ms/step\n",
            "Epoch 55/64\n",
            "95/95 - 17s - loss: 0.6279 - accuracy: 0.7610 - val_loss: 0.6694 - val_accuracy: 0.7593 - 17s/epoch - 180ms/step\n",
            "Epoch 56/64\n",
            "95/95 - 17s - loss: 0.6403 - accuracy: 0.7567 - val_loss: 0.6793 - val_accuracy: 0.7546 - 17s/epoch - 175ms/step\n",
            "Epoch 57/64\n",
            "95/95 - 17s - loss: 0.6341 - accuracy: 0.7570 - val_loss: 0.7316 - val_accuracy: 0.7323 - 17s/epoch - 175ms/step\n",
            "Epoch 58/64\n",
            "95/95 - 19s - loss: 0.6291 - accuracy: 0.7646 - val_loss: 0.8062 - val_accuracy: 0.7299 - 19s/epoch - 198ms/step\n",
            "Epoch 59/64\n",
            "95/95 - 17s - loss: 0.6172 - accuracy: 0.7673 - val_loss: 0.7875 - val_accuracy: 0.7431 - 17s/epoch - 177ms/step\n",
            "Epoch 60/64\n",
            "95/95 - 17s - loss: 0.6148 - accuracy: 0.7686 - val_loss: 0.7107 - val_accuracy: 0.7500 - 17s/epoch - 175ms/step\n",
            "Epoch 61/64\n",
            "95/95 - 16s - loss: 0.6133 - accuracy: 0.7623 - val_loss: 0.7031 - val_accuracy: 0.7377 - 16s/epoch - 171ms/step\n",
            "Epoch 62/64\n",
            "95/95 - 17s - loss: 0.6058 - accuracy: 0.7746 - val_loss: 0.7387 - val_accuracy: 0.7292 - 17s/epoch - 174ms/step\n",
            "Epoch 63/64\n",
            "95/95 - 16s - loss: 0.6153 - accuracy: 0.7690 - val_loss: 0.7243 - val_accuracy: 0.7477 - 16s/epoch - 173ms/step\n",
            "Epoch 64/64\n",
            "95/95 - 16s - loss: 0.5900 - accuracy: 0.7809 - val_loss: 0.6917 - val_accuracy: 0.7461 - 16s/epoch - 169ms/step\n"
          ]
        }
      ],
      "source": [
        "#compile the model\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "batch_size = 32\n",
        "epochs = 64\n",
        "history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs,\n",
        "                              validation_data = (X_test,y_test),\n",
        "                              verbose = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WxeFDdQaNZS",
        "outputId": "57456055-f2b7-454c-8b86-0e95ae57872a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 19ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 16ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 19ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 16ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 19ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 18ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 20ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 17ms/step\n",
            "41/41 [==============================] - 1s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "# let model identify the flower\n",
        "\n",
        "categories = np.sort(os.listdir(folder_dir))\n",
        "fig, ax = plt.subplots(6,6, figsize=(25,40))\n",
        "\n",
        "for i in range(6):\n",
        "    for j in range(6):\n",
        "        k = int(np.random.random_sample() * len(X_test))\n",
        "        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n",
        "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n",
        "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])],color='green')\n",
        "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE,SIZE,3), cmap='gray')\n",
        "        else:\n",
        "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n",
        "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])],color='red')\n",
        "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE,SIZE,3), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnJ_57moaNcp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}